{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuwvV8Tu+GrmIu0Wfc3MVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VickyKandale/Assignment_pyhton.pwskills/blob/main/Assignment_(Clustering_4)_30_April.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering-4"
      ],
      "metadata": {
        "id": "Lsz3FBpIKDu5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa3HiINyI3KQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Explain the concept of homogeneity and completeness in clustering evaluation. How are they calculated?"
      ],
      "metadata": {
        "id": "QoTs80RtKOFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homogeneity and completeness are two metrics used to evaluate the quality of clustering results. Homogeneity measures how well the data points within a cluster are similar to each other, while completeness measures how well all the data points that belong to the same class are assigned to the same cluster.\n",
        "\n",
        "Homogeneity is calculated as follows:\n",
        "```\n",
        "Homogeneity = 1 - (sum of intra-cluster distances)/(sum of all distances)\n",
        "```\n",
        "where:\n",
        "\n",
        "Intra-cluster distances are the distances between data points within the same cluster.\n",
        "All distances are the distances between all data points in the dataset.\n",
        "A high homogeneity score indicates that the data points within a cluster are very similar to each other. A low homogeneity score indicates that the data points within a cluster are not very similar to each other.\n",
        "\n",
        "Completeness is calculated as follows:\n",
        "```\n",
        "Completeness = 1 - (sum of inter-cluster distances)/(sum of all distances)\n",
        "```\n",
        "where:\n",
        "\n",
        "- Inter-cluster distances are the distances between data points in different clusters.\n",
        "\n",
        "A high completeness score indicates that all the data points that belong to the same class are assigned to the same cluster. A low completeness score indicates that there are data points that belong to the same class but are assigned to different clusters.\n",
        "\n",
        "Both homogeneity and completeness are important metrics for evaluating clustering results. A high homogeneity score indicates that the clusters are well-defined, while a high completeness score indicates that all the data points that belong to the same class are assigned to the same cluster.\n",
        "\n",
        "Here are some additional points about homogeneity and completeness:\n",
        "\n",
        "- Homogeneity and completeness are complementary metrics: A high homogeneity score indicates that the clusters are well-defined, while a high completeness score indicates that all the data points that belong to the same class are assigned to the same cluster. A good clustering result will have both a high homogeneity score and a high completeness score.\n",
        "- Homogeneity and completeness are not perfect metrics: No clustering algorithm can perfectly achieve both homogeneity and completeness. However, a good clustering algorithm will achieve a high score on both metrics.\n",
        "- Homogeneity and completeness can be used to compare different clustering algorithms: The homogeneity and completeness scores of different clustering algorithms can be used to compare the quality of the clustering results produced by each algorithm."
      ],
      "metadata": {
        "id": "9ZzdeNSNKVwP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wzSyjshKQGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What is the V-measure in clustering evaluation? How is it related to homogeneity and completeness?"
      ],
      "metadata": {
        "id": "UkgBoef_K7Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The V-measure is a clustering evaluation metric that quantifies the similarity between a clustering result and a reference (ground truth) clustering, taking into account both homogeneity and completeness.\n",
        "\n",
        "Homogeneity measures the extent to which each cluster contains only data points that belong to a single class in the reference clustering. It evaluates the purity of the clusters. Completeness, on the other hand, measures the extent to which all data points that belong to a particular class are assigned to the same cluster. It evaluates the extent to which a class is well-represented within a cluster.\n",
        "\n",
        "The V-measure combines these two measures to provide an overall evaluation of the clustering quality. It is calculated as the harmonic mean of homogeneity and completeness:\n",
        "```\n",
        "V = (1 + beta) * homogeneity * completeness / (beta * homogeneity + completeness)\n",
        "```\n",
        "The beta parameter is used to adjust the weighting between homogeneity and completeness. When beta = 1, the V-measure is the harmonic mean of homogeneity and completeness. A higher beta value emphasizes completeness, while a lower beta value emphasizes homogeneity.\n",
        "\n",
        "The V-measure ranges from 0 to 1, where 1 indicates a perfect clustering result that perfectly matches the reference clustering in terms of both homogeneity and completeness.\n",
        "\n",
        "By considering both homogeneity and completeness, the V-measure provides a balanced evaluation of the clustering performance. It is particularly useful when dealing with imbalanced datasets or when both the cluster structure and the class structure need to be taken into account.\n",
        "\n",
        "It's important to note that the V-measure requires a reference clustering (ground truth) for evaluation. In situations where a reference clustering is not available, other evaluation metrics such as silhouette score or adjusted Rand index can be used to assess the quality of the clustering."
      ],
      "metadata": {
        "id": "4wVNK-HUK-ED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. How is the Silhouette Coefficient used to evaluate the quality of a clustering result? What is the range of its values?"
      ],
      "metadata": {
        "id": "B9dNFoTfLDDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Silhouette Coefficient is a widely used clustering evaluation metric that measures the quality of a clustering result. It assesses the compactness and separation of clusters based on the distances between data points within and between clusters.\n",
        "\n",
        "The Silhouette Coefficient for a single data point is calculated as follows:\n",
        "```\n",
        "s = (b - a) / max(a, b)\n",
        "```\n",
        "where:\n",
        "\n",
        "- a is the average distance between the data point and other data points within the same cluster (intra-cluster distance).\n",
        "- b is the average distance between the data point and data points in the nearest neighboring cluster (inter-cluster distance).\n",
        "\n",
        "The Silhouette Coefficient for a clustering result is computed as the average of the silhouette values across all data points in the dataset.\n",
        "\n",
        "`The range of the Silhouette Coefficient is between -1 and 1:`\n",
        "\n",
        "A value close to +1 indicates that the data point is well-clustered, with a small average intra-cluster distance and a large average inter-cluster distance. This suggests a good separation between clusters.\n",
        "A value close to 0 indicates that the data point is on or near the decision boundary between two neighboring clusters.\n",
        "A value close to -1 indicates that the data point may have been assigned to the wrong cluster, as the average intra-cluster distance is larger than the average inter-cluster distance.\n",
        "The overall Silhouette Coefficient for a clustering result is commonly reported as the average value across all data points. A higher average Silhouette Coefficient indicates a better clustering result with well-separated and internally compact clusters.\n",
        "\n",
        "When interpreting the Silhouette Coefficient, it's important to consider the context of the data and the problem at hand. It is a relative measure and does not provide absolute guarantees about the quality of the clustering. It should be used in combination with other evaluation metrics and domain knowledge to assess the clustering performance effectively."
      ],
      "metadata": {
        "id": "wQdhJyBILLVj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sqpdIysK748"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. How is the Davies-Bouldin Index used to evaluate the quality of a clustering result? What is the range of its values?"
      ],
      "metadata": {
        "id": "KJ4lV-76LIP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Davies-Bouldin index (DBI) is a metric used to evaluate the quality of a clustering result. It is a measure of the separation between clusters. A low DBI score indicates that the clusters are well-separated, while a high DBI score indicates that the clusters are not well-separated.\n",
        "\n",
        "The DBI is calculated as follows:\n",
        "```\n",
        "DBI = 1/n * sum(max(Sj/Sj') for j in 1,...,n)\n",
        "```\n",
        "where:\n",
        "\n",
        "- n is the number of clusters\n",
        "- Sj is the average intra-cluster distance for cluster j\n",
        "- Sj' is the minimum inter-cluster distance for cluster j\n",
        "\n",
        "The DBI has a range of 0 to +infinity. A DBI of 0 indicates that the clusters are perfectly separated, while a DBI of +infinity indicates that the clusters are not separated at all.\n",
        "\n",
        "The DBI is a relatively simple metric to calculate, and it is often used in conjunction with other metrics, such as homogeneity and completeness, to evaluate the quality of a clustering result.\n",
        "\n",
        "Here are some additional points about the Davies-Bouldin index:\n",
        "\n",
        "- The DBI is not a perfect metric: The DBI can be sensitive to outliers, and it can also be affected by the choice of distance metric.\n",
        "- The DBI can be used to compare different clustering algorithms: The DBI scores of different clustering algorithms can be used to compare the quality of the clustering results produced by each algorithm.\n",
        "- The DBI is a complementary metric: The DBI is a measure of the separation between clusters, while homogeneity and completeness are measures of the similarity within clusters. A good clustering result will have a low DBI score, a high homogeneity score, and a high completeness score."
      ],
      "metadata": {
        "id": "fq5ZFz52LZ_t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BbFW8l2rLKle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Can a clustering result have a high homogeneity but low completeness? Explain with an example."
      ],
      "metadata": {
        "id": "ndFjcvTwLrJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, it is possible for a clustering result to have a high homogeneity but low completeness. This can occur when the clustering algorithm emphasizes the purity of clusters but fails to capture all the data points belonging to a particular class.\n",
        "\n",
        "To illustrate this, let's consider an example where we have a dataset of customer reviews on a product. The dataset contains reviews from two classes: positive reviews and negative reviews. We want to cluster the reviews based on their content.\n",
        "\n",
        "Suppose we apply a clustering algorithm that successfully separates the reviews into distinct clusters. In Cluster 1, we have reviews that are predominantly positive, with only a few negative reviews mixed in. In Cluster 2, we have reviews that are mainly negative, but there are some positive reviews included.\n",
        "\n",
        "In this scenario, Cluster 1 demonstrates high homogeneity because it consists mostly of positive reviews, with only a few negative reviews present. The majority of the reviews within Cluster 1 belong to the positive class, achieving high purity or homogeneity within that cluster.\n",
        "\n",
        "However, Cluster 1 may have low completeness because not all the positive reviews are correctly assigned to this cluster. Some positive reviews might be mistakenly included in Cluster 2 due to similarities in their content or other factors. As a result, the completeness is reduced because not all positive reviews are represented within the cluster where they should belong.\n",
        "\n",
        "Cluster 2, on the other hand, may have lower homogeneity due to the presence of positive reviews within the predominantly negative cluster. However, it may have higher completeness as most of the negative reviews are correctly assigned to this cluster.\n",
        "\n",
        "In summary, a clustering result can have high homogeneity (due to cluster purity) but low completeness (due to misclassification of certain data points). This can occur when the algorithm prioritizes internal cluster coherence but struggles to capture all instances of a particular class, resulting in incomplete representation of that class within the clusters."
      ],
      "metadata": {
        "id": "For18BYsLsuV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YjA6mq9qLsLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. How can the V-measure be used to determine the optimal number of clusters in a clustering algorithm?"
      ],
      "metadata": {
        "id": "ucUCgEG6Lv7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The V-measure is a metric used to evaluate the quality of a clustering result. It is a combination of homogeneity and completeness, and it has a range of 0 to 1. A V-measure of 1 indicates that the clustering result is perfect, while a V-measure of 0 indicates that the clustering result is random.\n",
        "\n",
        "The V-measure can be used to determine the optimal number of clusters in a clustering algorithm by plotting the V-measure as a function of the number of clusters. The optimal number of clusters is the number that produces the highest V-measure score.\n",
        "\n",
        "Here is an example of how the V-measure can be used to determine the optimal number of clusters:\n",
        "```\n",
        "# Calculate the V-measure for different numbers of clusters\n",
        "v_measures = []\n",
        "for k in range(2, 10):\n",
        "  clustering = kmeans(data, k)\n",
        "  v_measures.append(v_measure(clustering))\n",
        "\n",
        "# Plot the V-measure as a function of the number of clusters\n",
        "plt.plot(range(2, 10), v_measures)\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"V-measure\")\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "The plot shows that the V-measure score increases as the number of clusters increases. However, the V-measure score starts to plateau after a certain number of clusters. In this example, the optimal number of clusters is 4.\n",
        "\n",
        "Here are some additional points about the V-measure:\n",
        "\n",
        "- The V-measure is a good metric for evaluating clustering results: The V-measure is a combination of homogeneity and completeness, which makes it a good metric for evaluating clustering results.\n",
        "- The V-measure can be used to compare different clustering algorithms: The V-measure scores of different clustering algorithms can be used to compare the quality of the clustering results produced by each algorithm.\n",
        "-The V-measure is not a perfect metric: The V-measure can be sensitive to outliers, and it can also be affected by the choice of distance metric."
      ],
      "metadata": {
        "id": "2Kws3jXlL7P1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4R_qlXDrL0ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7. What are some advantages and disadvantages of using the Silhouette Coefficient to evaluate a clustering result?"
      ],
      "metadata": {
        "id": "jL6Hu5j4L05l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of using the Silhouette Coefficient for clustering evaluation:\n",
        "\n",
        "1. Intuitive Interpretation: The Silhouette Coefficient provides a single value between -1 and 1, making it easy to understand and compare across different clustering results. Higher values indicate better clustering quality.\n",
        "\n",
        "2. No Assumptions about Cluster Shape: The Silhouette Coefficient does not assume any particular shape for the clusters, making it applicable to a wide range of clustering algorithms and data distributions.\n",
        "\n",
        "3. Consideration of Compactness and Separation: The Silhouette Coefficient takes into account both the average intra-cluster distance (compactness) and the average inter-cluster distance (separation). It assesses the overall quality of the clusters based on these measures.\n",
        "\n",
        "4. Handles Different Cluster Sizes: The Silhouette Coefficient can handle clusters of varying sizes, as it calculates the average distances individually for each data point, rather than considering the overall cluster sizes.\n",
        "\n",
        "Disadvantages and limitations of the Silhouette Coefficient:\n",
        "\n",
        "1. Sensitivity to the Number of Clusters: The Silhouette Coefficient is influenced by the number of clusters in the analysis. It tends to favor solutions with a higher number of clusters, as smaller clusters can lead to better average distances.\n",
        "\n",
        "2. Sensitivity to Data Scaling: The Silhouette Coefficient is sensitive to the scaling of the data. It is recommended to scale the data appropriately before calculating the distances to ensure meaningful results.\n",
        "\n",
        "3. Lack of Ground Truth: The Silhouette Coefficient is an unsupervised evaluation metric and does not rely on a ground truth clustering. Therefore, it cannot account for cases where the ground truth clustering itself may be ambiguous or imperfect.\n",
        "\n",
        "4. Limited to Numeric Data: The Silhouette Coefficient is primarily designed for numeric data and distance-based clustering algorithms. It may not be directly applicable to categorical or text data without appropriate distance or similarity measures.\n",
        "\n",
        "5. Not Suitable for Overlapping Clusters: The Silhouette Coefficient assumes that data points belong to exactly one cluster and does not handle overlapping clusters. It may provide misleading results in cases where data points can belong to multiple clusters simultaneously.\n",
        "\n",
        "It's important to note that the Silhouette Coefficient should be used in conjunction with other evaluation metrics and domain knowledge to gain a comprehensive understanding of the clustering quality. Its limitations should be considered, and alternative metrics should be explored for specific clustering scenarios or data types."
      ],
      "metadata": {
        "id": "hVE-7EzLMSh2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Tl02nluL3Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q8. What are some limitations of the Davies-Bouldin Index as a clustering evaluation metric? How can they be overcome?"
      ],
      "metadata": {
        "id": "07wRUJPQMIh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Davies-Bouldin Index (DBI) is a metric used to evaluate the quality of a clustering result. It is a measure of the separation between clusters. A low DBI score indicates that the clusters are well-separated, while a high DBI score indicates that the clusters are not well-separated.\n",
        "\n",
        "The DBI has a number of limitations, including:\n",
        "\n",
        "- It is sensitive to outliers: The DBI can be sensitive to outliers, which means that a single outlier can significantly increase the DBI score.\n",
        "- It is not robust to changes in the distance metric: The DBI can be sensitive to changes in the distance metric, which means that the DBI score can vary significantly depending on the choice of distance metric.\n",
        "- It does not take into account the structure or distribution of data: The DBI does not take into account the structure or distribution of data, which means that it can be misleading for data that is not spherical or evenly distributed.\n",
        "\n",
        "There are a number of ways to overcome the limitations of the DBI, including:\n",
        "\n",
        "- Using a robust distance metric: A robust distance metric is less sensitive to outliers, which can help to reduce the impact of outliers on the DBI score.\n",
        "- Using a cluster validation method: A cluster validation method is a statistical technique that can be used to evaluate the quality of clustering results. Cluster validation methods can be used to identify clusters that are not well-separated or that are not representative of the data.\n",
        "- Using a combination of metrics: The DBI can be used in conjunction with other metrics, such as homogeneity and completeness, to get a more comprehensive assessment of the quality of a clustering result."
      ],
      "metadata": {
        "id": "uk17e5VNMhLs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_l0-NPtMKHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q9. What is the relationship between homogeneity, completeness, and the V-measure? Can they have different values for the same clustering result?"
      ],
      "metadata": {
        "id": "D6BWVm65MKjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Homogeneity and completeness are both metrics used to evaluate the quality of clustering results. Homogeneity measures how well the data points within a cluster are similar to each other, while completeness measures how well all the data points that belong to the same class are assigned to the same cluster.\n",
        "\n",
        "The V-measure is a metric that combines homogeneity and completeness. It is calculated as the harmonic mean of homogeneity and completeness. The V-measure has a range of 0 to 1, where 0 indicates a random clustering result and 1 indicates a perfect clustering result.\n",
        "\n",
        "Yes, homogeneity, completeness, and the V-measure can have different values for the same clustering result. This is because homogeneity and completeness measure different aspects of the clustering result. Homogeneity measures the similarity within clusters, while completeness measures the separation between clusters. The V-measure takes into account both homogeneity and completeness, so it can be different from either of them.\n",
        "\n",
        "For example, consider a clustering result where all the data points in each cluster are very similar to each other, but the clusters are not well-separated. In this case, the homogeneity score will be high, but the completeness score will be low. The V-measure will be somewhere in between, depending on the relative values of the homogeneity and completeness scores.\n",
        "\n",
        "Here is a table that summarizes the relationship between homogeneity, completeness, and the V-measure:\n",
        "\n",
        "Metric\t-------------Description\t--------------------Range\n",
        "\n",
        "Homogeneity -------\tMeasures the similarity within clusters\t--------0 to 1\n",
        "\n",
        "Completeness\t-------Measures the separation between clusters---------\t0 to 1\n",
        "\n",
        "V-measure\t------Combines homogeneity and completeness-------\t0 to 1"
      ],
      "metadata": {
        "id": "MksPRaikM_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTaQOmZJMNqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q10. How can the Silhouette Coefficient be used to compare the quality of different clustering algorithms on the same dataset? What are some potential issues to watch out for?"
      ],
      "metadata": {
        "id": "EmbZFWtfMtud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Silhouette Coefficient can be used to compare the quality of different clustering algorithms on the same dataset by calculating the Silhouette Coefficient for each algorithm and comparing the average values or distributions across the algorithms. Here's how it can be done:\n",
        "\n",
        "- Apply different clustering algorithms: Run multiple clustering algorithms on the same dataset, each with its own set of parameters or configurations. Examples of clustering algorithms include k-means, hierarchical clustering, DBSCAN, or Gaussian mixture models.\n",
        "\n",
        "- Calculate the Silhouette Coefficient: For each clustering algorithm, calculate the Silhouette Coefficient for each data point in the dataset. Then, compute the average Silhouette Coefficient across all data points. This step is performed for each algorithm under consideration.\n",
        "\n",
        "- Compare the Silhouette Coefficients: Compare the average Silhouette Coefficient values obtained from different clustering algorithms. A higher average Silhouette Coefficient indicates better clustering quality and better separation between clusters.\n",
        "\n",
        "Potential issues to watch out for when using the Silhouette Coefficient for comparing clustering algorithms:\n",
        "\n",
        "- Sensitivity to data preprocessing: The Silhouette Coefficient can be sensitive to data preprocessing steps such as scaling, normalization, or feature selection. Ensure consistent and appropriate preprocessing across all algorithms to avoid biases in the evaluation.\n",
        "\n",
        "- Dependency on algorithm parameters: Different clustering algorithms may have various parameters or configurations that can affect the results. It's important to explore a range of parameter settings for each algorithm and choose the best-performing combination.\n",
        "\n",
        "- Sensitivity to initialization: Clustering algorithms like k-means are sensitive to initializations. The choice of initial centroids or seeds can impact the resulting clusters and, subsequently, the Silhouette Coefficient. Running the algorithm multiple times with different initializations and reporting the best result is recommended.\n",
        "\n",
        "- Interpretation based on domain knowledge: The Silhouette Coefficient provides a numerical measure of clustering quality, but its interpretation should be combined with domain knowledge. Consider the specific characteristics of the dataset, the nature of the problem, and any inherent assumptions or constraints.\n",
        "\n",
        "- Context-specific evaluation: The suitability of the Silhouette Coefficient may vary depending on the specific clustering task and dataset. It's important to consider other evaluation metrics, such as visual inspection of the clusters, domain-specific metrics, or external validation measures if a ground truth clustering is available.\n",
        "\n",
        "By carefully addressing these potential issues, the Silhouette Coefficient can serve as a useful tool for comparing the performance of different clustering algorithms on the same dataset. However, it is recommended to employ multiple evaluation metrics and take a holistic approach when assessing clustering quality."
      ],
      "metadata": {
        "id": "SwYT6qSvM0ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIg1OYlGMvMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}