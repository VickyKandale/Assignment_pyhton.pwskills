{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsyRanpVoIaEfRAiypBljt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VickyKandale/Assignment_pyhton.pwskills/blob/main/17_Mar_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values"
      ],
      "metadata": {
        "id": "MJk7xEWU6Q0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values are a common occurrence in datasets, and they refer to the absence of data for one or more variables in a particular observation. Missing values can occur for various reasons, such as data collection errors, data corruption, or intentionally left blank due to privacy concerns.\n",
        "\n",
        "It is essential to handle missing values in a dataset because they can affect the accuracy of the analysis, predictions, and machine learning models. Ignoring or deleting the missing values can lead to biased results, reduced statistical power, and decreased predictive performance.\n",
        "\n",
        "There are several algorithms that are not affected by missing values, such as:\n",
        "\n",
        "`Decision Trees:` \n",
        "\n",
        "Decision trees can handle missing values by using surrogate splits to replace the missing values with the best possible alternative.\n",
        "\n",
        "`Random Forests:`\n",
        "\n",
        " Random forests use multiple decision trees and aggregate their predictions, making them robust to missing values.\n",
        "\n",
        "`K-Nearest Neighbors:`\n",
        "\n",
        " K-NN algorithm can handle missing values by ignoring the missing value in the distance calculation or imputing it using the mean value or the most frequent value.\n",
        "\n",
        "`Naive Bayes:`\n",
        "\n",
        "\n",
        "Naive Bayes algorithm can handle missing values by ignoring the missing values during the probability calculations.\n",
        "\n",
        "Support Vector Machines: \n",
        "\n",
        "SVM can handle missing values by ignoring the missing values or by replacing them with the mean or median of the feature.\n",
        "\n",
        "In conclusion, it is essential to handle missing values in a dataset to ensure the accuracy and reliability of the analysis and models. Several algorithms can handle missing values by either ignoring them or imputing them with a suitable alternative."
      ],
      "metadata": {
        "id": "SdXfz-MP7Bw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCM1yK-U6C6-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2: List down techniques used to handle missing data.  Give an example of each with python code."
      ],
      "metadata": {
        "id": "4emX2uPM6THD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several techniques that can be used to handle missing data in a dataset. Here are some commonly used techniques with an example in Python:\n",
        "\n",
        "1. Removal of missing data: The simplest approach is to remove the missing data from the dataset. However, this approach can lead to loss of valuable information."
      ],
      "metadata": {
        "id": "PVuGnJDgKBbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a sample dataframe with missing values\n",
        "df = pd.DataFrame({'A': [1, 2, None, 4],\n",
        "                   'B': [5, None, 7, 8],\n",
        "                   'C': [9, 10, 11, None]})\n",
        "\n",
        "# drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "oguEldoy6WF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb07800-fd8d-4f4b-e1db-bcae97642f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B    C\n",
            "0  1.0  5.0  9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Imputation:` \n",
        "This involves filling in missing data with substitute values. This can be done using various techniques such as mean, median, mode, or even machine learning algorithms."
      ],
      "metadata": {
        "id": "7PFJabMiOBhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df=sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "zFoyYK72Nyfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Value check\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQrj8djiN6Af",
        "outputId": "eafca03b-cb9c-46b9-e432-ec9adc719f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived         0\n",
              "pclass           0\n",
              "sex              0\n",
              "age            177\n",
              "sibsp            0\n",
              "parch            0\n",
              "fare             0\n",
              "embarked         2\n",
              "class            0\n",
              "who              0\n",
              "adult_male       0\n",
              "deck           688\n",
              "embark_town      2\n",
              "alive            0\n",
              "alone            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by checking decribing data set the age value has integers and deck has str data value\n",
        "# Mean value inputation\n",
        "df['age_mean']=df['age'].fillna(df['age'].mean())\n",
        "df['age_median']=df['age'].fillna(df['age'].median())"
      ],
      "metadata": {
        "id": "bLWD0M5rOKYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['age_median','age_mean','age']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1XOfTuKnOOJN",
        "outputId": "58c9c304-374f-46e9-de1f-624685b8bb7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age_median   age_mean   age\n",
              "0          22.0  22.000000  22.0\n",
              "1          38.0  38.000000  38.0\n",
              "2          26.0  26.000000  26.0\n",
              "3          35.0  35.000000  35.0\n",
              "4          35.0  35.000000  35.0\n",
              "..          ...        ...   ...\n",
              "886        27.0  27.000000  27.0\n",
              "887        19.0  19.000000  19.0\n",
              "888        28.0  29.699118   NaN\n",
              "889        26.0  26.000000  26.0\n",
              "890        32.0  32.000000  32.0\n",
              "\n",
              "[891 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6a42aef-0d22-4387-8a36-5debe032ccb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age_median</th>\n",
              "      <th>age_mean</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>27.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>19.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>28.0</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>26.0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>32.0</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6a42aef-0d22-4387-8a36-5debe032ccb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6a42aef-0d22-4387-8a36-5debe032ccb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6a42aef-0d22-4387-8a36-5debe032ccb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tYHmpIpOPaN",
        "outputId": "384d840e-6e7a-4ed7-e846-e48eefae94ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived         0\n",
              "pclass           0\n",
              "sex              0\n",
              "age            177\n",
              "sibsp            0\n",
              "parch            0\n",
              "fare             0\n",
              "embarked         2\n",
              "class            0\n",
              "who              0\n",
              "adult_male       0\n",
              "deck           688\n",
              "embark_town      2\n",
              "alive            0\n",
              "alone            0\n",
              "age_mean         0\n",
              "age_median       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now check the deck column data\n",
        "df['deck'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osv8c2ZPOVGl",
        "outputId": "e2b7c784-fdd5-4371-a25a-8285c3acda7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NaN, 'C', 'E', 'G', 'D', 'A', 'B', 'F']\n",
              "Categories (7, object): ['A', 'B', 'C', 'D', 'E', 'F', 'G']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['deck'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxjLT-mOXOP",
        "outputId": "c705b39a-6d26-4abb-ee31-d3ca2a144e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "688"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['age'].notna()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "rznO1xjQOcCV",
        "outputId": "bb345954-158a-4533-cb21-f8ce606ddf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
              "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
              "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
              "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
              "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
              "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
              "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
              "885         0       3  female  39.0      0      5  29.1250        Q   Third   \n",
              "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
              "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
              "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
              "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
              "\n",
              "       who  adult_male deck  embark_town alive  alone  age_mean  age_median  \n",
              "0      man        True  NaN  Southampton    no  False      22.0        22.0  \n",
              "1    woman       False    C    Cherbourg   yes  False      38.0        38.0  \n",
              "2    woman       False  NaN  Southampton   yes   True      26.0        26.0  \n",
              "3    woman       False    C  Southampton   yes  False      35.0        35.0  \n",
              "4      man        True  NaN  Southampton    no   True      35.0        35.0  \n",
              "..     ...         ...  ...          ...   ...    ...       ...         ...  \n",
              "885  woman       False  NaN   Queenstown    no  False      39.0        39.0  \n",
              "886    man        True  NaN  Southampton    no   True      27.0        27.0  \n",
              "887  woman       False    B  Southampton   yes   True      19.0        19.0  \n",
              "889    man        True    C    Cherbourg   yes   True      26.0        26.0  \n",
              "890    man        True  NaN   Queenstown    no   True      32.0        32.0  \n",
              "\n",
              "[714 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d00f8428-9d8f-4f93-888e-caf6fb7b0678\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "      <th>age_mean</th>\n",
              "      <th>age_median</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>38.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>29.1250</td>\n",
              "      <td>Q</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>39.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>Second</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>27.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>B</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d00f8428-9d8f-4f93-888e-caf6fb7b0678')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d00f8428-9d8f-4f93-888e-caf6fb7b0678 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d00f8428-9d8f-4f93-888e-caf6fb7b0678');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode=df[df['age'].notna()]['deck'].mode()[0]"
      ],
      "metadata": {
        "id": "hnLJeVVmOfI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Zme9O4mbOiqV",
        "outputId": "b69879cb-868d-48ce-9ced-dfffe72dc2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['deck_new']=df['deck'].fillna(mode)"
      ],
      "metadata": {
        "id": "UoYjl1bfOlGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['deck_new','deck']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "AKsPRFvSOnWH",
        "outputId": "4d51847d-e2e1-423e-f4e3-36914dd86117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    deck_new deck\n",
              "0          C  NaN\n",
              "1          C    C\n",
              "2          C  NaN\n",
              "3          C    C\n",
              "4          C  NaN\n",
              "..       ...  ...\n",
              "886        C  NaN\n",
              "887        B    B\n",
              "888        C  NaN\n",
              "889        C    C\n",
              "890        C  NaN\n",
              "\n",
              "[891 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b2ee7a4-d38a-4320-8a60-156188a75eee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deck_new</th>\n",
              "      <th>deck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b2ee7a4-d38a-4320-8a60-156188a75eee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b2ee7a4-d38a-4320-8a60-156188a75eee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b2ee7a4-d38a-4320-8a60-156188a75eee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['embarked'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbY7oXo-OtJw",
        "outputId": "06e04757-88e9-4aac-9894-a5fde93fd2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['embarked'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjnNwkkAOw60",
        "outputId": "81dede68-4a8d-4a1e-a737-1562440796d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['S', 'C', 'Q', nan], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode=df[df['age'].notna()]['embarked'].mode()[0]"
      ],
      "metadata": {
        "id": "T4D1ymVTO0QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embarked_mode']=df['embarked'].fillna(mode)"
      ],
      "metadata": {
        "id": "CZJeuSV-O2M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.dropna(axis=1)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgVWxRbZO6hE",
        "outputId": "0ea3c603-adbb-415a-bbb5-6e84c5f9358b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived           0\n",
              "pclass             0\n",
              "sex                0\n",
              "age              177\n",
              "sibsp              0\n",
              "parch              0\n",
              "fare               0\n",
              "embarked           2\n",
              "class              0\n",
              "who                0\n",
              "adult_male         0\n",
              "deck             688\n",
              "embark_town        2\n",
              "alive              0\n",
              "alone              0\n",
              "age_mean           0\n",
              "age_median         0\n",
              "deck_new           0\n",
              "embarked_mode      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we checked the handled the missing value and cleaned the data using Mean,Mode & Median Imputation technique.\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2TvbYboPIWV",
        "outputId": "bbfd9b36-a757-4d45-9e7d-0d53031d7f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived         0\n",
              "pclass           0\n",
              "sex              0\n",
              "sibsp            0\n",
              "parch            0\n",
              "fare             0\n",
              "class            0\n",
              "who              0\n",
              "adult_male       0\n",
              "alive            0\n",
              "alone            0\n",
              "age_mean         0\n",
              "age_median       0\n",
              "deck_new         0\n",
              "embarked_mode    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "tIAP-1BlQlBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3679462c-d1df-48ed-c11f-088aa8de8ff4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count  Dtype   \n",
            "---  ------         --------------  -----   \n",
            " 0   survived       891 non-null    int64   \n",
            " 1   pclass         891 non-null    int64   \n",
            " 2   sex            891 non-null    object  \n",
            " 3   sibsp          891 non-null    int64   \n",
            " 4   parch          891 non-null    int64   \n",
            " 5   fare           891 non-null    float64 \n",
            " 6   class          891 non-null    category\n",
            " 7   who            891 non-null    object  \n",
            " 8   adult_male     891 non-null    bool    \n",
            " 9   alive          891 non-null    object  \n",
            " 10  alone          891 non-null    bool    \n",
            " 11  age_mean       891 non-null    float64 \n",
            " 12  age_median     891 non-null    float64 \n",
            " 13  deck_new       891 non-null    category\n",
            " 14  embarked_mode  891 non-null    object  \n",
            "dtypes: bool(2), category(2), float64(3), int64(4), object(4)\n",
            "memory usage: 80.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
      ],
      "metadata": {
        "id": "ZrmqnlkS6WiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced data refers to a situation where the number of observations in each class of a classification problem is not equal. In other words, one class has a significantly larger number of observations than the other(s). For example, in a medical dataset, the number of patients with a particular rare disease may be much smaller than those without the disease.\n",
        "\n",
        "If imbalanced data is not handled, it can lead to biased and inaccurate models. The machine learning algorithms may prioritize the majority class and ignore the minority class, leading to poor performance for the minority class. The resulting model may have high accuracy for the majority class, but poor accuracy for the minority class, which is often the class of interest in applications such as fraud detection, disease diagnosis, or rare event detection.\n",
        "\n",
        "Moreover, imbalanced data can also result in overfitting, where the model memorizes the majority class instead of learning the underlying patterns in the data. This can result in poor generalization performance on new and unseen data.\n",
        "\n",
        "Therefore, it is essential to handle imbalanced data by employing techniques such as undersampling, oversampling, or a combination of both. Undersampling involves removing some observations from the majority class to balance the class distribution, while oversampling involves creating new synthetic observations for the minority class. A combination of both techniques can also be used to improve the performance of machine learning algorithms on imbalanced data. Other techniques such as cost-sensitive learning, ensemble methods, and anomaly detection can also be used to handle imbalanced data."
      ],
      "metadata": {
        "id": "OqjeprMH8NEx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycm28vny6ZUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required."
      ],
      "metadata": {
        "id": "H1ODHosz6Z0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up-sampling and down-sampling are techniques used in machine learning to handle imbalanced datasets, where one class has significantly more samples than the other(s).\n",
        "\n",
        "Down-sampling involves randomly removing samples from the majority class to balance the dataset. This can lead to loss of information and reduced accuracy, especially when the dataset is already small.\n",
        "\n",
        "Up-sampling, on the other hand, involves increasing the number of samples in the minority class by replicating existing samples or generating synthetic samples using techniques such as SMOTE (Synthetic Minority Over-sampling Technique). This can help to balance the dataset and improve the performance of the machine learning model.\n",
        "\n",
        "Here's an example to illustrate when up-sampling and down-sampling might be required:\n",
        "\n",
        "Suppose we have a dataset with 1000 samples, of which 900 belong to Class A and 100 belong to Class B. This is a highly imbalanced dataset, with Class A being the majority class and Class B being the minority class. If we train a machine learning model on this dataset without balancing the classes, the model will likely perform poorly on Class B, as it has very few samples to learn from.\n",
        "\n",
        "In this scenario, we might consider using up-sampling techniques to generate more samples for Class B. We could use SMOTE to generate synthetic samples based on the existing samples in Class B, increasing the number of samples to 500, for example. This would help to balance the dataset and improve the model's performance on Class B.\n",
        "\n",
        "Alternatively, we could use down-sampling techniques to randomly remove samples from Class A, reducing the number of samples to, say, 500. This would balance the dataset, but could also result in loss of information and reduced accuracy, especially if the dataset is already small.\n",
        "\n",
        "In summary, up-sampling and down-sampling are techniques used to handle imbalanced datasets in machine learning, and their use depends on the specific requirements of the machine learning model and the nature of the data."
      ],
      "metadata": {
        "id": "FhXt1XEP8C2e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMI0OnWI6cpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5: What is data Augmentation? Explain SMOTE."
      ],
      "metadata": {
        "id": "seHNqcl_6dLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation is a technique used to increase the size of a training dataset by creating new synthetic samples from the original data. Data augmentation is particularly useful when the original dataset is small, imbalanced, or lacks diversity.\n",
        "\n",
        "One popular method of data augmentation is SMOTE (Synthetic Minority Over-sampling Technique). SMOTE creates new synthetic samples of the minority class by interpolating between existing minority class samples. The algorithm selects a random minority class sample and finds its k nearest neighbors in the feature space. SMOTE then creates new synthetic samples by randomly selecting one of the k nearest neighbors and interpolating between the selected neighbor and the original minority class sample.\n",
        "\n",
        "The level of interpolation is controlled by a user-defined parameter called the \"sampling ratio.\" The sampling ratio determines the number of synthetic samples to be generated for each original minority class sample. SMOTE can also be used with other oversampling techniques, such as ADASYN (Adaptive Synthetic Sampling) or Borderline-SMOTE, which adapt the sampling ratio based on the local density of the minority class.\n",
        "\n",
        "SMOTE is a powerful technique for handling imbalanced datasets as it can increase the diversity of the minority class and reduce the overfitting caused by duplicating existing samples. SMOTE has been shown to improve the performance of various machine learning algorithms on imbalanced datasets, including decision trees, support vector machines, and neural networks. However, it is essential to use SMOTE with care and avoid overfitting to the minority class, which can lead to reduced performance on new and unseen data."
      ],
      "metadata": {
        "id": "pGf6AYV18e9z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ciewhew6fEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
      ],
      "metadata": {
        "id": "NfWSPpje6hCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers are data points that lie far away from the majority of the other data points in a dataset. They can be caused by measurement errors, data entry errors, or other anomalies in the data. Outliers can have a significant impact on statistical analyses and machine learning models, as they can skew the results and reduce the accuracy of the models.\n",
        "\n",
        "It is essential to handle outliers for several reasons:\n",
        "\n",
        "Outliers can significantly impact statistical analyses such as mean, standard deviation, and correlation. Outliers can skew the results of these analyses and lead to incorrect conclusions.\n",
        "\n",
        "Outliers can also have a significant impact on machine learning models. Many machine learning algorithms are sensitive to outliers, and outliers can negatively impact the accuracy of the models.\n",
        "\n",
        "Outliers can also affect data visualization. If the outliers are not handled, they can lead to distorted graphs and visualizations, which can be misleading.\n",
        "\n",
        "Handling outliers is important to improve the accuracy of statistical analyses and machine learning models. There are several ways to handle outliers, including:\n",
        "\n",
        "Removing outliers: This involves removing the outliers from the dataset. However, this approach should be used with caution, as removing too many outliers can result in a loss of information and potentially biased results.\n",
        "\n",
        "Transforming the data: Transforming the data can help to reduce the impact of outliers. For example, using log transformations can help to reduce the impact of extreme values.\n",
        "\n",
        "Imputing missing values: If the outliers are caused by missing data, imputing the missing values can help to reduce the impact of outliers.\n",
        "\n",
        "In summary, outliers are data points that lie far away from the majority of the other data points in a dataset. Handling outliers is essential to improve the accuracy of statistical analyses and machine learning models. There are several ways to handle outliers, including removing outliers, transforming the data, and imputing missing values."
      ],
      "metadata": {
        "id": "hJHCEiij8osx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOXRg0rW6h1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
      ],
      "metadata": {
        "id": "TLAA34dg6jv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with missing data is an important step in data analysis to ensure that your results are accurate and reliable. Here are some techniques you can use to handle missing data in your analysis:\n",
        "\n",
        "Delete missing data: If the missing data is limited to a small portion of the dataset, you can simply delete the rows with missing data. However, this approach can lead to a reduction in sample size, which may impact the accuracy of your analysis.\n",
        "\n",
        "Impute missing data: Imputation is the process of filling in missing data with estimated values. There are several methods for imputing missing data, including mean imputation, mode imputation, and regression imputation. Mean imputation replaces missing values with the mean of the non-missing values. Mode imputation replaces missing values with the mode of the non-missing values. Regression imputation predicts missing values using a regression model based on the non-missing values.\n",
        "\n",
        "Use multiple imputations: Multiple imputations involve generating multiple imputed datasets using different imputation methods and then analyzing each imputed dataset separately. This approach accounts for the uncertainty in the imputed values and can produce more accurate results.\n",
        "\n",
        "\n",
        "It is important to note that the choice of technique for handling missing data depends on the characteristics of the dataset and the research question being addressed."
      ],
      "metadata": {
        "id": "_EXaIHzwDVeN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OY2DsGJP6khz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
      ],
      "metadata": {
        "id": "0o_u1MKc6nVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several strategies that you can use to determine if the missing data is missing at random or if there is a pattern to the missing data:\n",
        "\n",
        "* Check for patterns in the missing data: Look for any patterns in the missing data, such as missing data being concentrated in certain variables or groups. This could indicate that the missing data is not random.\n",
        "\n",
        "* Analyze missing data mechanisms: There are three main types of missing data mechanisms: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). Analyzing these mechanisms can help you determine if the missing data is random or not.\n",
        "\n",
        "* Impute missing values: Impute the missing data using different methods such as mean, median, or mode. Then compare the results to see if there are any significant differences. If there are significant differences, it could indicate that the missing data is not random.\n",
        "\n",
        "* Correlate missingness with other variables: Look for correlations between missingness and other variables in the dataset. For example, if missingness is correlated with income, it could indicate that the missing data is not random.\n",
        "\n",
        "* Use statistical tests: Use statistical tests such as the Little’s MCAR test to determine if the missing data is missing at random or not. This test compares the missing data pattern to a completely random pattern and tests if they are significantly different."
      ],
      "metadata": {
        "id": "iTj8MjTWD-a9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fjc9j7Px6orM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
      ],
      "metadata": {
        "id": "BuIwTYgn6rUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced datasets, where one class is underrepresented, are a common problem in machine learning, particularly in medical diagnosis projects. Here are some strategies you can use to evaluate the performance of your machine learning model on an imbalanced dataset:\n",
        "\n",
        "`Use evaluation metrics that account for class imbalance:`\n",
        "\n",
        " The standard accuracy metric may not be the best evaluation metric for imbalanced datasets, as it can be misleading. Instead, use evaluation metrics such as precision, recall, F1-score, or area under the receiver operating characteristic (ROC) curve. These metrics take into account the true positive rate (TPR) and false positive rate (FPR) of the model.\n",
        "\n",
        "`Use resampling techniques: `\n",
        "\n",
        "Resampling techniques such as oversampling and undersampling can help balance the dataset. Oversampling involves creating synthetic data points for the minority class, while undersampling involves removing data points from the majority class. However, these techniques may lead to overfitting or underfitting the model, respectively.\n",
        "\n",
        "`Use ensemble methods:`\n",
        "\n",
        " Ensemble methods such as bagging, boosting, and stacking can be used to improve the performance of the model on imbalanced datasets. These methods combine the predictions of multiple models to produce a more accurate prediction.\n",
        "\n",
        "Adjust the decision threshold:\n",
        "\n",
        " The decision threshold is the value used to classify an observation into a particular class. By adjusting the decision threshold, you can control the trade-off between precision and recall. For example, lowering the decision threshold can increase the recall at the cost of lower precision.\n",
        "\n",
        "It is important to note that the choice of strategy for handling imbalanced datasets depends on the specific characteristics of the dataset and the research question being addressed. It is also important to properly evaluate the performance of the model using appropriate evaluation metrics and to avoid overfitting to the imbalanced dataset."
      ],
      "metadata": {
        "id": "F1PsdilUEmhN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxPOxOMLF1Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
      ],
      "metadata": {
        "id": "0jCJMtD_6uAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with an unbalanced dataset where the majority class dominates, the following methods can be employed to balance the dataset and down-sample the majority class:\n",
        "\n",
        "`Random under-sampling:` \n",
        "\n",
        "This involves randomly removing data from the majority class until the dataset is balanced. However, this method may lead to a loss of important information if the dataset is already small.\n",
        "\n",
        "`Cluster-based under-sampling:` \n",
        "\n",
        "This involves clustering the majority class data and selecting only the representative data points from each cluster to balance the dataset. This method can help preserve the information from the majority class.\n",
        "\n",
        "`Tomek links:`\n",
        "\n",
        " This method involves removing the majority class samples that are closest to the minority class samples. This helps create more distinct boundaries between the two classes.\n",
        "\n",
        "`Synthetic minority over-sampling technique (SMOTE):` \n",
        "\n",
        "This method involves creating synthetic samples of the minority class by randomly selecting samples and creating new synthetic samples by interpolating between them. This helps increase the minority class size while maintaining its diversity.\n",
        "\n",
        "Ensemble techniques:\n",
        "\n",
        " Ensemble techniques involve combining multiple models to improve the classification performance. For example, the Balanced Random Forest (BRF) algorithm combines random under-sampling with random forest algorithm to balance the dataset and improve classification performance.\n",
        "\n",
        "It is important to note that while balancing the dataset can improve model performance, it may also lead to a loss of information. Therefore, it is important to carefully consider the trade-off between balancing the dataset and preserving information."
      ],
      "metadata": {
        "id": "j71NRtQVFFBs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IVgh1eTB6xmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
      ],
      "metadata": {
        "id": "pju8fVsr6zdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with a dataset that is unbalanced with a low percentage of occurrences, it is important to balance the dataset before training any machine learning models. Here are some methods that can be employed to balance the dataset and up-sample the minority class:\n",
        "\n",
        "`Oversampling:` \n",
        "\n",
        "Oversampling is a technique where the minority class is up-sampled by creating synthetic samples. There are various methods to generate synthetic samples, including random sampling and synthetic minority over-sampling technique (SMOTE). SMOTE is a popular oversampling method that creates synthetic samples by interpolating between the minority class samples.\n",
        "\n",
        "`Undersampling:` \n",
        "\n",
        "Undersampling is a technique where the majority class is down-sampled by removing samples randomly. This method can be useful when there is a large number of majority class samples, and it may lead to faster training times.\n",
        "\n",
        "`Combination of oversampling and undersampling:`\n",
        "\n",
        " A combination of oversampling and undersampling can be employed to balance the dataset. This can be done by oversampling the minority class and undersampling the majority class until a desired balance is achieved.\n",
        "\n",
        "Using different evaluation metrics: \n",
        "\n",
        "In cases where it is difficult to balance the dataset, evaluation metrics such as precision, recall, and F1-score that account for class imbalance can be used to evaluate the performance of the model.\n",
        "\n",
        "It is important to note that each of these methods has its advantages and disadvantages, and the choice of the method depends on the specifics of the dataset and the research question being addressed. Additionally, it is important to avoid overfitting to the up-sampled minority class and to perform proper evaluation of the model using appropriate metrics."
      ],
      "metadata": {
        "id": "SguNZseMFjj0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gq8QQcLy67_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
